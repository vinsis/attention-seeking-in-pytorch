Loss at iteration 0: 2.30981755
Loss at iteration 100: 0.61434495
Loss at iteration 200: 0.10967793
Loss at iteration 300: 0.03431129
Loss at iteration 400: 0.01729980
Loss at iteration 500: 0.01073055
Loss at iteration 600: 0.00738640
Loss at iteration 700: 0.00547667
Loss at iteration 800: 0.00423107
Loss at iteration 900: 0.00335608
Loss at iteration 1000: 0.00274973
Loss at iteration 1100: 0.00228901
Loss at iteration 1200: 0.00193853
Loss at iteration 1300: 0.00165625
Loss at iteration 1400: 0.00143261
Loss at iteration 1500: 0.00124760
Loss at iteration 1600: 0.00109930
Loss at iteration 1700: 0.00097179
Loss at iteration 1800: 0.00087271
Loss at iteration 1900: 0.00077515
Loss at iteration 2000: 0.00069857
Loss at iteration 2100: 0.00063028
Loss at iteration 2200: 0.00057068
Loss at iteration 2300: 0.00051975
Loss at iteration 2400: 0.00047445
Loss at iteration 2500: 0.00043354
Stopping training now

